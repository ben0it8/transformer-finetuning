{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* use model described in:\n",
    "https://colab.research.google.com/drive/1iDHCYIrWswIKp-n-pOg69xLoZO09MEgf#scrollTo=zjzTkJGl1J0l - Done\n",
    "\n",
    "* build flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (4.32.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch) (1.16.3)\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /opt/conda/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2019.6.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (4.32.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.9.160)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.16.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2019.6.16)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.160 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (1.12.160)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.160->boto3->pytorch_pretrained_bert) (2.8.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.160->boto3->pytorch_pretrained_bert) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.160->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Requirement already satisfied: pytorch-ignite in /opt/conda/lib/python3.6/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from pytorch-ignite) (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->pytorch-ignite) (1.16.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas tqdm\n",
    "!pip install torch pytorch_pretrained_bert pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import tarfile\n",
    "import urllib\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path('./data').resolve()\n",
    "IMDB = DATA_DIR/'aclImdb'\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "def download_url(url:str, dest:str, overwrite:bool=True, show_progress=True, \n",
    "                 chunk_size=1024*1024, timeout=4, retries=5)->None:\n",
    "    \"Download `url` to `dest` unless it exists and not `overwrite`.\"\n",
    "    dest = Path(dest)/os.path.basename(url)\n",
    "    if os.path.exists(dest) and not overwrite: \n",
    "        print(\"File already existing\")\n",
    "        return\n",
    "\n",
    "    s = requests.Session()\n",
    "    s.mount('http://',requests.adapters.HTTPAdapter(max_retries=retries))\n",
    "    u = s.get(url, stream=True, timeout=timeout)\n",
    "    try: file_size = int(u.headers[\"Content-Length\"])\n",
    "    except: show_progress = False\n",
    "    print(f\"Downloading {url}\")\n",
    "    with open(dest, 'wb') as f:\n",
    "        nbytes = 0\n",
    "        if show_progress: \n",
    "            pbar = tqdm(range(file_size), leave=False)\n",
    "        try:\n",
    "            for chunk in u.iter_content(chunk_size=chunk_size):\n",
    "                nbytes += len(chunk)\n",
    "                if show_progress: pbar.update(nbytes)\n",
    "                f.write(chunk)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"Download failed after {retries} retries.\")\n",
    "            import sys;sys.exit(1)\n",
    "        finally:\n",
    "            return str(dest)\n",
    "        \n",
    "def untar(file_path, dest:str):\n",
    "    print(f\"Untar {os.path.basename(file_path)} to {dest}\")\n",
    "    with tarfile.open(file_path) as tf:\n",
    "        tf.extractall(path=str(dest))\n",
    "    os.remove(file_path)\n",
    "    return str(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download imdb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152201ecf9104e6d8695967daec40a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84125825), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untar aclImdb_v1.tar.gz to /workspace/data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/data'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = download_url(url, '/tmp', overwrite=True)\n",
    "untar(file_path, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 63M\r\n",
      "drwxr-xr-x. 4 root root 105 Jun 26  2011 aclImdb\r\n",
      "-rw-r--r--. 1 root root 32M Jul  4 14:43 dev.tsv\r\n",
      "-rw-r--r--. 1 root root 32M Jul  4 14:43 train.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read imdb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_html(raw):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    clean = re.sub(cleanr, '  ', raw)\n",
    "    return re.sub(' +', ' ', clean)\n",
    "\n",
    "\n",
    "def read_imdb(imdb_dir: str, text_col='text', label_col='label'):\n",
    "\n",
    "    \"Read imdb data to {'label', 'text'} format\"\n",
    "    imdb_dir = Path(imdb_dir)\n",
    "    datasets = {}\n",
    "    for t in ['train', 'test']:        \n",
    "        texts, labels = [], []\n",
    "        for p in ['pos', 'neg']:\n",
    "            for file in tqdm((imdb_dir/'train'/p).glob(\"*.txt\"), desc=f'reading {t}/{p}'):\n",
    "                with open(file, 'r') as fin:\n",
    "                    text = fin.readlines()[0].replace(r'\\n', ' ')\n",
    "                    text = clean_html(text).strip()\n",
    "                    texts +=  [text]\n",
    "                    labels += [p]\n",
    "                    \n",
    "        df = pd.DataFrame(\n",
    "            {label_col: labels, text_col: texts})\n",
    "        datasets[t] = df.sample(frac=1)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading train/pos: 12500it [00:02, 4832.21it/s]\n",
      "reading train/neg: 12500it [00:02, 5095.42it/s]\n",
      "reading test/pos: 12500it [00:01, 9276.68it/s]\n",
      "reading test/neg: 12500it [00:01, 9406.30it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = read_imdb(IMDB)\n",
    "\n",
    "labels = list(set(datasets['train']['label'].tolist()))\n",
    "label2int = {label: i for i, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs - args: base model parameters, adapt_args: fine-tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "\n",
    "LOG_DIR = \"./logs/\"\n",
    "CACHE_DIR = \"./cache/\"\n",
    "\n",
    "NUM_MAX_POSITIONS = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "AdaptationConfig = namedtuple('AdaptationConfig',\n",
    "  field_names=\"num_classes, dropout, initializer_range, batch_size, lr, max_norm, n_epochs,\"\n",
    "              \"n_warmup, valid_pct, gradient_accumulation_steps, device,\"\n",
    "              \"log_dir, dataset_cache\")\n",
    "adapt_args = AdaptationConfig(\n",
    "               2          , 0.1    , 0.02             , 32        , 6.5e-5, 1.0   , 3,\n",
    "               10      , 0.1           , 1, device,\n",
    "               LOG_DIR, CACHE_DIR+'dataset_cache.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import (OpenAIGPTTokenizer, OpenAIGPTModel,\n",
    "                                     OpenAIAdam, cached_path, WEIGHTS_NAME, CONFIG_NAME)\n",
    "\n",
    "from pytorch_pretrained_bert.modeling_openai import OpenAIGPTPreTrainedModel, OpenAIGPTMultipleChoiceHead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTFromPretrainedWithClfHead(nn.Module):\n",
    "    \n",
    "    def __init__(self,  base_model, fine_tuning_config, output_attentions=False, keep_multihead_output=False):\n",
    "        super().__init__()\n",
    "        self.transformer = OpenAIGPTModel.from_pretrained(base_model)\n",
    "        embed_dim = self.transformer.tokens_embed.weight.shape[-1]\n",
    "        \n",
    "        self.transformer.output_attentions = output_attentions\n",
    "        self.transformer.keep_multihead_output = keep_multihead_output\n",
    "        \n",
    "        self.config = fine_tuning_config\n",
    "        self.classification_head = nn.Linear(embed_dim, self.config.num_classes)\n",
    "        \n",
    "        # init only clf head\n",
    "        self.init_weights(self.classification_head)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, nn.LayerNorm)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        if isinstance(module, (nn.Linear, nn.LayerNorm)) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "    \n",
    "    def set_num_special_tokens(self, num_special_tokens, predict_special_tokens=True):\n",
    "        \n",
    "        self.config.predict_special_tokens = self.transformer.config.predict_special_tokens = predict_special_tokens\n",
    "        self.transformer.set_num_special_tokens(num_special_tokens)\n",
    "    \n",
    "    def forward(self, input_ids, clf_labels=None, position_ids=None, token_type_ids=None):\n",
    "        \"\"\"\n",
    "            - input_ids: [batch_size, seq_len], word embeddings of sequence\n",
    "            - position_ids: same shape, position ids in range [0, config.n_positions -1[, position embeddings\n",
    "            - token_type_ids: same shape, optional for third type of embedding to input tokens in sequences\n",
    "        \n",
    "        output: \n",
    "         - hidden_states: list of all encoded hidden states in the model (length: num layers+1 for the output of embeddings),\n",
    "                          [batch_size, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        hidden_states = self.transformer(input_ids, position_ids=position_ids, \n",
    "                                         token_type_ids=token_type_ids)\n",
    "        \n",
    "        # hidden_states [B, S, H] - pick last along 2nd dimension\n",
    "        hidden_states = hidden_states[:, -1, :]\n",
    "        logits = self.classification_head(hidden_states)\n",
    "        \n",
    "        if clf_labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), clf_labels.view(-1))\n",
    "            return logits, loss\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "code_folding": [
     7,
     43
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \n",
    "    CLS = '[CLS]'\n",
    "    PAD = '[PAD]'\n",
    "    \n",
    "    def __init__(self, tokenizer, label2id, num_max_positions=512):\n",
    "        self.tokenizer=tokenizer\n",
    "        self.label2id = label2id\n",
    "        self.num_labels = len(label2id)\n",
    "        self.num_max_positions = num_max_positions\n",
    "        \n",
    "    \n",
    "    def process_example(self, example):\n",
    "        assert len(example) == 2\n",
    "        label, text = example[0], example[1]\n",
    "        assert isinstance(text, str)\n",
    "        \n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter(\"ignore\")\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        if len(tokens) >= self.num_max_positions:\n",
    "            tokens = tokens[:self.num_max_positions-1] \n",
    "            ids =  self.tokenizer.convert_tokens_to_ids(tokens) + [self.tokenizer.vocab[self.CLS]]\n",
    "        else:\n",
    "            pad = [self.tokenizer.vocab[self.PAD]] * (self.num_max_positions-len(tokens)-1)\n",
    "            ids =  self.tokenizer.convert_tokens_to_ids(tokens) + [self.tokenizer.vocab[self.CLS]] + pad\n",
    "        \n",
    "#         ids =  self.tokenizer.convert_tokens_to_ids(tokens)         \n",
    "#         if len(ids) >= self.num_max_positions:\n",
    "#             ids = ids[:self.num_max_positions-1] + [self.tokenizer.vocab[self.CLS]]\n",
    "#         else:\n",
    "#             pad = [self.tokenizer.vocab[self.PAD]] * (self.num_max_positions-len(ids)-1)\n",
    "#             ids = ids + [self.tokenizer.vocab[self.CLS]] + pad\n",
    "        return ids, self.label2id[label]\n",
    "    \n",
    "\n",
    "def create_dataset(df, processor, batch_size=32, shuffle=False, valid_pct=None, \n",
    "                   text_col=\"text\", label_col=\"label\"):\n",
    "    \"Process rows in `df` with `processor` and return a DataLoader\"\n",
    "    \n",
    "    features, labels = [], []\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ids, lbl = processor.process_example([row.label, row.text])\n",
    "        features += [ids]\n",
    "        labels += [lbl]\n",
    "    \n",
    "    dataset = TensorDataset(\n",
    "                    torch.tensor(features, dtype=torch.long), \n",
    "                    torch.tensor(labels, dtype=torch.long))\n",
    "    \n",
    "    if valid_pct is not None:\n",
    "        \n",
    "        valid_size = int(valid_pct * len(df))\n",
    "        train_size = len(df) - valid_size\n",
    "        valid_dataset, train_dataset = random_split(dataset, [valid_size, train_size])\n",
    "        \n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)    \n",
    "        return train_loader, valid_loader\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return data_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "processor = DataProcessor(tokenizer, label2int, num_max_positions=NUM_MAX_POSITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = datasets[\"train\"].sample(500)\n",
    "df_test = datasets[\"test\"].sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec62de902e94494e8f72646595f27259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a234aff289664ee0b623127f29ad3990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = create_dataset(df_train, processor, batch_size=adapt_args.batch_size, \n",
    "                                    valid_pct=adapt_args.valid_pct)\n",
    "\n",
    "test_dl = create_dataset(df_test, processor, batch_size=adapt_args.batch_size, valid_pct=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"openai-gpt\"\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(base_model)\n",
    "\n",
    "FineTuningConfig = namedtuple('FineTuningConfig', \n",
    "                              field_names=\"base_model, num_classes, initializer_range\")\n",
    "\n",
    "fine_tuning_config = FineTuningConfig(base_model, 2, 0.02)\n",
    "\n",
    "\n",
    "smodel = GPTFromPretrainedWithClfHead(fine_tuning_config.base_model, fine_tuning_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(model):\n",
    "    import numpy as np\n",
    "    mp = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum(np.prod(p.size()) for p in mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=410, out_features=2, bias=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_model.classification_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-57-a45d39264aef>(78)forward()\n",
      "-> if clf_labels is not None:\n",
      "(Pdb) clf_logits.shape\n",
      "torch.Size([8, 2])\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-09079f4028ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madaptation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_tokens_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-a45d39264aef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, clf_tokens_mask, clf_labels, padding_mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclf_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-a45d39264aef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, clf_tokens_mask, clf_labels, padding_mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclf_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input = input.to(device)\n",
    "adaptation_model(input, clf_tokens_mask = (input==101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare fine-tuning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "code_folding": [
     7,
     25
    ]
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import RunningAverage, Accuracy \n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.contrib.handlers import CosineAnnealingScheduler, PiecewiseLinear, create_lr_scheduler_with_warmup, ProgressBar\n",
    "\n",
    "optimizer = torch.optim.Adam(adaptation_model.parameters(), lr=adapt_args.lr)\n",
    "\n",
    "def update(engine, batch):\n",
    "    \n",
    "    adaptation_model.train()\n",
    "    inputs, labels = (t.to(adapt_args.device) for t in batch)\n",
    "    \n",
    "    inputs = inputs.transpose(0, 1).contiguous() # [S, B]\n",
    "    _, loss = adaptation_model(inputs, \n",
    "                               clf_tokens_mask = (inputs == tokenizer.vocab[processor.CLS]), \n",
    "                               clf_labels=labels)\n",
    "    loss = loss / adapt_args.gradient_accumulation_steps\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(adaptation_model.parameters(), adapt_args.max_norm)\n",
    "    if engine.state.iteration % adapt_args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "def inference(engine, batch):\n",
    "    adaptation_model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch, labels = (t.to(adapt_args.device) for t in batch)\n",
    "        inputs = batch.transpose(0, 1).contiguous()\n",
    "        logits = adaptation_model(inputs,\n",
    "                                  clf_tokens_mask = (inputs == tokenizer.vocab[processor.CLS]),\n",
    "                                  padding_mask = (batch == tokenizer.vocab[processor.PAD]))\n",
    "    return logits, labels\n",
    "                              \n",
    "trainer = Engine(update)\n",
    "evaluator = Engine(inference)\n",
    "\n",
    "# Attache metric to evaluator & evaluation to trainer: evaluate on valid set after each epoch\n",
    "Accuracy().attach(evaluator, \"accuracy\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(valid_dl)\n",
    "    print(f\"validation epoch: {engine.state.epoch} acc: {100*evaluator.state.metrics['accuracy']}\")\n",
    "          \n",
    "# Learning rate schedule: linearly warm-up to lr and then to zero\n",
    "scheduler = PiecewiseLinear(optimizer, 'lr', [(0, 0.0), (adapt_args.n_warmup, adapt_args.lr),\n",
    "                                              (len(train_dl)*adapt_args.n_epochs, 0.0)])\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
    "\n",
    "\n",
    "# Add progressbar with loss\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n",
    "ProgressBar(persist=True).attach(trainer, metric_names=['loss'])\n",
    "\n",
    "# Save checkpoints and finetuning config\n",
    "checkpoint_handler = ModelCheckpoint(adapt_args.log_dir, 'finetuning_checkpoint', \n",
    "                                     save_interval=1, require_empty=False)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {'mymodel': adaptation_model})\n",
    "torch.save(args, os.path.join(adapt_args.log_dir, 'fine_tuning_args.bin'))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets fine-tune on imdb!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a4a92c29da41eb8b39ea6a9acd8b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=141), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation epoch: 1 acc: 84.39999999999999\n",
      "CPU times: user 23.2 s, sys: 41.7 s, total: 1min 4s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f7f004e0fd0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "trainer.run(train_dl, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test results - acc: 86.860\n"
     ]
    }
   ],
   "source": [
    "evaluator.run(test_dl)\n",
    "print(f\"test results - acc: {100*evaluator.state.metrics['accuracy']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def predict(model, tokenizer, int2label, input=\"test\"):\n",
    "    tok = tokenizer.tokenize(input)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tok) + [tokenizer.vocab['[CLS]']]\n",
    "    tensor = torch.tensor(ids, dtype=torch.long)\n",
    "    tensor = tensor.to(device)\n",
    "    tensor = tensor.reshape(1, -1)\n",
    "    tensor_in = tensor.transpose(0, 1).contiguous() # [S, 1]\n",
    "    logits = adaptation_model(tensor_in,\n",
    "                              clf_tokens_mask = (tensor_in == tokenizer.vocab['[CLS]']),\n",
    "                              padding_mask = (tensor == tokenizer.vocab['[PAD]']))\n",
    "    val, _ = torch.max(logits, 0)\n",
    "    val = F.softmax(val, dim=0).detach().cpu().numpy()    \n",
    "    return {int2label[val.argmax()]: val.max(),\n",
    "            int2label[val.argmin()]: val.min()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.58218247, 'pos': 0.41781756}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2label = {i:label for label,i in label2int.items()}\n",
    "\n",
    "predict(adaptation_model, tokenizer, int2label, input = \"This movie is poorly directed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 0.98019135, 'neg': 0.019808643}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(adaptation_model, tokenizer, int2label, input = \"I just love how the actors are playing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://bottlepy.org/bottle.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH gpu-remote Py 3.6",
   "language": "",
   "name": "rik_ssh_gpu_remote_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
